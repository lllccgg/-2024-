#!/usr/bin/env python3
"""
LeNet-5 PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼çš„å‘½ä»¤è¡Œå·¥å…·
ç”¨æ³•: python export_to_onnx.py --model_path lenet5_armor.pth --output_path lenet5_armor.onnx
"""

import torch
import torch.nn as nn
import argparse
import os
import sys

# å®šä¹‰LeNet-5ç½‘ç»œç»“æ„ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
class LeNet5(nn.Module):
    def __init__(self, num_classes=9):
        super(LeNet5, self).__init__()
        
        # ç¬¬ä¸€å±‚å·ç§¯å±‚ï¼šè¾“å…¥1é€šé“ï¼Œè¾“å‡º6é€šé“ï¼Œå·ç§¯æ ¸5x5ï¼Œpadding=same
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)
        # ç¬¬ä¸€å±‚æ± åŒ–å±‚ï¼š2x2å¹³å‡æ± åŒ–
        self.pool1 = nn.AvgPool2d(kernel_size=2)
        # ç¬¬äºŒå±‚å·ç§¯å±‚ï¼šè¾“å…¥6é€šé“ï¼Œè¾“å‡º16é€šé“ï¼Œå·ç§¯æ ¸5x5
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        # ç¬¬äºŒå±‚æ± åŒ–å±‚ï¼š2x2å¹³å‡æ± åŒ–
        self.pool2 = nn.AvgPool2d(kernel_size=2)
        # ç¬¬ä¸‰å±‚å·ç§¯å±‚ï¼šè¾“å…¥16é€šé“ï¼Œè¾“å‡º120é€šé“ï¼Œå·ç§¯æ ¸6x6ï¼ˆä¿®æ­£ï¼‰
        self.conv3 = nn.Conv2d(16, 120, kernel_size=6)
        # å±•å¹³å±‚
        self.flatten = nn.Flatten()
        # å…¨è¿æ¥å±‚ï¼šè¾“å…¥120ï¼Œè¾“å‡º84
        self.fc1 = nn.Linear(120, 84)
        # å…¨è¿æ¥å±‚ï¼šè¾“å…¥84ï¼Œè¾“å‡º9ï¼ˆè£…ç”²æ¿æ•°å­—è¯†åˆ«ï¼š0-8ï¼‰
        self.fc2 = nn.Linear(84, num_classes)

    def forward(self, x):
        # ç¬¬ä¸€å±‚å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = torch.relu(self.conv1(x))
        x = self.pool1(x)
        # ç¬¬äºŒå±‚å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = torch.relu(self.conv2(x))
        x = self.pool2(x)
        # ç¬¬ä¸‰å±‚å·ç§¯ + æ¿€æ´»
        x = torch.relu(self.conv3(x))
        # å±•å¹³
        x = self.flatten(x)
        # å…¨è¿æ¥å±‚ + æ¿€æ´»
        x = torch.relu(self.fc1(x))
        # è¾“å‡ºå±‚
        x = self.fc2(x)
        return x

def export_to_onnx(model_path, output_path, num_classes=9, input_size=(1, 1, 32, 32)):
    """
    å°†PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼
    
    Args:
        model_path (str): PyTorchæ¨¡å‹æ–‡ä»¶è·¯å¾„(.pth)
        output_path (str): è¾“å‡ºONNXæ–‡ä»¶è·¯å¾„(.onnx)
        input_size (tuple): è¾“å…¥å¼ é‡å°ºå¯¸ (batch_size, channels, height, width)
    """
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ '{model_path}' ä¸å­˜åœ¨!")
        return False
    
    try:
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = LeNet5(num_classes=num_classes)
        
        # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # å¤„ç†ä¸åŒçš„ä¿å­˜æ ¼å¼
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                model.load_state_dict(checkpoint)
        else:
            model.load_state_dict(checkpoint)
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“Š æ¨¡å‹ç»“æ„:")
        print(model)
        
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥å¼ é‡
        dummy_input = torch.randn(input_size)
        print(f"ğŸ¯ è¾“å…¥å°ºå¯¸: {input_size}")
        
        # å¯¼å‡ºä¸ºONNX
        print(f"ğŸ”„ æ­£åœ¨å¯¼å‡ºONNXæ¨¡å‹: {output_path}")
        
        torch.onnx.export(
            model,                          # æ¨¡å‹
            dummy_input,                    # è™šæ‹Ÿè¾“å…¥
            output_path,                    # è¾“å‡ºè·¯å¾„
            export_params=True,             # å¯¼å‡ºå‚æ•°
            opset_version=11,               # ONNXæ“ä½œé›†ç‰ˆæœ¬
            do_constant_folding=True,       # å¸¸é‡æŠ˜å ä¼˜åŒ–
            input_names=['input'],          # è¾“å…¥åç§°
            output_names=['output'],        # è¾“å‡ºåç§°
            dynamic_axes={                  # åŠ¨æ€è½´ï¼ˆæ”¯æŒä¸åŒbatch sizeï¼‰
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        print(f"âœ… ONNXå¯¼å‡ºæˆåŠŸ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        # éªŒè¯å¯¼å‡ºçš„ONNXæ¨¡å‹
        try:
            import onnx
            onnx_model = onnx.load(output_path)
            onnx.checker.check_model(onnx_model)
            print(f"âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡!")
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            print(f"ğŸ“Š ONNXæ¨¡å‹ä¿¡æ¯:")
            print(f"   - è¾“å…¥: {onnx_model.graph.input[0].name} {[d.dim_value for d in onnx_model.graph.input[0].type.tensor_type.shape.dim]}")
            print(f"   - è¾“å‡º: {onnx_model.graph.output[0].name} {[d.dim_value for d in onnx_model.graph.output[0].type.tensor_type.shape.dim]}")
            
        except ImportError:
            print("âš ï¸  è­¦å‘Š: æœªå®‰è£…onnxåº“ï¼Œè·³è¿‡æ¨¡å‹éªŒè¯")
            print("   å¯é€šè¿‡ 'pip install onnx' å®‰è£…")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(description='å°†LeNet-5 PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼')
    parser.add_argument('--model_path', '-m', type=str, default='lenet5_armor.pth',
                       help='PyTorchæ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: lenet5_armor.pth)')
    parser.add_argument('--output_path', '-o', type=str, default='lenet5_armor.onnx',
                       help='è¾“å‡ºONNXæ–‡ä»¶è·¯å¾„ (é»˜è®¤: lenet5_armor.onnx)')
    parser.add_argument('--num_classes', '-n', type=int, default=9,
                       help='æ¨¡å‹è¾“å‡ºç±»åˆ«æ•° (é»˜è®¤: 9, è£…ç”²æ¿æ•°å­—0-8)')
    parser.add_argument('--batch_size', '-b', type=int, default=1,
                       help='æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 1)')
    parser.add_argument('--height', type=int, default=32,
                       help='è¾“å…¥å›¾åƒé«˜åº¦ (é»˜è®¤: 32)')
    parser.add_argument('--width', type=int, default=32,
                       help='è¾“å…¥å›¾åƒå®½åº¦ (é»˜è®¤: 32)')
    
    args = parser.parse_args()
    
    print("ğŸš€ LeNet-5 PyTorch â†’ ONNX è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    # æ„å»ºè¾“å…¥å°ºå¯¸
    input_size = (args.batch_size, 1, args.height, args.width)
    
    # æ‰§è¡Œå¯¼å‡º
    success = export_to_onnx(args.model_path, args.output_path, args.num_classes, input_size)
    
    if success:
        print("\nğŸ‰ è½¬æ¢å®Œæˆ!")
        print(f"ğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print(f"   - C++éƒ¨ç½²: ä½¿ç”¨ONNX Runtime")
        print(f"   - Pythonæ¨ç†: ä½¿ç”¨onnxruntimeåº“")
        print(f"   - æ¨¡å‹ä¼˜åŒ–: å¯ä½¿ç”¨onnx-simplifierè¿›ä¸€æ­¥ä¼˜åŒ–")
        sys.exit(0)
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()